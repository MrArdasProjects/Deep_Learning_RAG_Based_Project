# ğŸ‘½ The War of the Worlds - RAG Q&A System

A Retrieval-Augmented Generation (RAG) system for answering questions about H.G. Wells' classic novel "The War of the Worlds" using LangChain, Google Gemini API, and ChromaDB.

## ğŸ¯ Project Overview

This project is part of EEE 517 Deep Learning Methods and Applications course. It implements a RAG system that:
- Processes and chunks a 200-page PDF book
- Creates vector embeddings using Google Gemini Embeddings
- Stores embeddings in ChromaDB for efficient retrieval
- Answers questions using Gemini Pro LLM
- Provides an interactive Streamlit interface

## ğŸ› ï¸ Technology Stack

- **LLM:** Google Gemini Pro
- **Embeddings:** Google Gemini Embeddings (models/embedding-001)
- **Vector Database:** ChromaDB
- **Framework:** LangChain
- **UI:** Streamlit
- **PDF Processing:** PyPDF

## ğŸ“¦ Installation

1. Clone the repository or download the files

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Make sure `The_War_of_the_Worlds_NT.pdf` is in the project directory

## ğŸš€ Usage

### Option 1: Streamlit Web Interface (Recommended)

Run the interactive web interface:
```bash
streamlit run streamlit_app.py
```

This will open a browser window where you can:
- Ask questions about the book
- View conversation history
- See source documents for each answer
- Use sample questions

### Option 2: Command Line

Run the RAG system directly:
```bash
python rag_system.py
```

This will:
1. Load and process the PDF
2. Create vector embeddings (first run only)
3. Run test questions
4. Display answers with sources

### Option 3: Use as a Library

```python
from rag_system import RAGSystem

# Initialize
rag = RAGSystem(pdf_path="The_War_of_the_Worlds_NT.pdf")
rag.initialize()

# Ask questions
result = rag.query("What is the main plot of the story?")
print(result["answer"])
```

## âš™ï¸ Configuration

Edit `config.py` to customize:
- `CHUNK_SIZE`: Size of text chunks (default: 1000)
- `CHUNK_OVERLAP`: Overlap between chunks (default: 200)
- `TEMPERATURE`: LLM temperature (default: 0.3)
- `TOP_K`: Number of relevant chunks to retrieve (default: 5)

## ğŸ“ Sample Questions

- Who is the main character?
- What is the book about?
- How do the Martians attack Earth?
- What happens to the Martians in the end?
- Who is the artilleryman?
- What is the red weed?

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ The_War_of_the_Worlds_NT.pdf  # Source book
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ config.py                      # Configuration settings
â”œâ”€â”€ rag_system.py                  # Core RAG implementation
â”œâ”€â”€ streamlit_app.py              # Web interface
â”œâ”€â”€ chroma_db/                    # Vector database (auto-created)
â””â”€â”€ README.md                     # This file
```

## ğŸ”§ How It Works

1. **Document Loading:** PDF is loaded and split into pages
2. **Text Chunking:** Pages are split into ~1000 character chunks with overlap
3. **Embedding:** Each chunk is converted to a 768-dimensional vector using Gemini
4. **Vector Storage:** Embeddings are stored in ChromaDB for fast retrieval
5. **Query Processing:** User question is embedded and similar chunks are retrieved
6. **Answer Generation:** Gemini Pro generates an answer based on retrieved context

## ğŸ“Š Performance

- **Book Size:** ~200 pages
- **Total Chunks:** ~400-600 (depending on book length)
- **Embedding Dimension:** 768
- **Retrieval Time:** <1 second
- **Answer Generation:** 2-5 seconds

## ğŸ“ Course Information

- **Course:** EEE 517 Deep Learning Methods and Applications
- **Instructor:** AyÃ§a Kumluca TopallÄ±
- **Term:** Fall 2025
- **Due Date:** December 30, 2025

## ğŸ“š References

- H.G. Wells - The War of the Worlds
- [LangChain Documentation](https://python.langchain.com/)
- [Google Gemini API](https://ai.google.dev/)
- [ChromaDB Documentation](https://docs.trychroma.com/)

## âš ï¸ Notes

- First run will take longer as it processes the PDF and creates embeddings
- Subsequent runs will be faster as it loads the existing vector database
- To force recreation of the vector database, set `force_reload=True` in initialization
- API rate limits: 15,000 requests/minute for Gemini API (free tier)

## ğŸ¤ Contributing

This is a course project. Feel free to fork and modify for your own learning purposes!

## ğŸ“„ License

This project is for educational purposes only.


